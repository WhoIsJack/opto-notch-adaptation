{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN - *sim* Spot Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os, csv\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "from skimage import io\n",
    "from skimage.feature import blob_log\n",
    "from skimage.filters import threshold_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "img_dir = r'..\\Data\\Images\\Sim'\n",
    "out_dir = r'..\\Data\\Measurements\\Sim'\n",
    "\n",
    "min_sigma = 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all relevant files\n",
    "\n",
    "walk = os.walk(img_dir)\n",
    "img_paths = []\n",
    "for w in walk:\n",
    "    for f in w[-1]:\n",
    "        if '_zmax' in f and 'sim' in f and f.endswith('.tif'):\n",
    "            img_paths.append(os.path.join(w[0], f))\n",
    "            \n",
    "for img_path in img_paths: \n",
    "    print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the RNG\n",
    "\n",
    "# Note: I only noticed that `skimage.feature.blob_log` has a probabilistic\n",
    "#       component when rerunning this for code release. As a consequence,\n",
    "#       the results are slightly different each time this code is rerun,\n",
    "#       though this does not qualitatively change the end results, as one\n",
    "#       would hope.\n",
    "#       The `Measurements` data included in this repo are the exact values\n",
    "#       used in the paper. If this code is rerun, slightly different values\n",
    "#       will be produced. Adding the seeding step below ensures that they\n",
    "#       will be identical each time such a rerun is performed.\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(img_path, min_sigma=0.7):\n",
    "    \n",
    "    # Report\n",
    "    print(\"Working on:\", img_path, end='')\n",
    "    \n",
    "    # Load\n",
    "    img = io.imread(img_path)\n",
    "    print(\" -- Loaded shape:\", img.shape)\n",
    "    \n",
    "    # Subtract background\n",
    "    bg = np.array([ndi.gaussian_filter(img[z], 10) \n",
    "                   for z in range(img.shape[0])])\n",
    "    img_bgsub = img - bg\n",
    "    img_bgsub[img < bg] = 0\n",
    "    \n",
    "    # Detect spots\n",
    "    blobs = [blob_log(img_bgsub[t], min_sigma=min_sigma, max_sigma=5) \n",
    "             for t in range(img.shape[0])]\n",
    "    \n",
    "    # Bbox helper funcs\n",
    "    get_bb_bot = lambda l, s : max([int(np.floor(l-s/2)), 0])\n",
    "    get_bb_top = lambda l, s, ims : min([int(np.floor(l+s/2)), ims])\n",
    "    \n",
    "    # Generate differently sized bounding boxes for measurements\n",
    "    median_sigma = np.median(np.concatenate(blobs)[:,2])\n",
    "    pct90_sigma = np.percentile(np.concatenate(blobs)[:,2], 90)\n",
    "    \n",
    "    # Bbox results dict\n",
    "    bbox_dict = {'median_sigma' : [],\n",
    "                 'pct90_sigma'  : [],\n",
    "                 'indiv_sigma'  : []}\n",
    "\n",
    "    # Compute bounding boxes\n",
    "    for t in range(img.shape[0]):\n",
    "        bboxes_median = []\n",
    "        bboxes_pct90  = []\n",
    "        bboxes_indiv  = []\n",
    "\n",
    "        for spot in range(blobs[t].shape[0]):\n",
    "            coords = blobs[t][spot][:2]\n",
    "\n",
    "            size = 3 * median_sigma\n",
    "            bbox_x = slice(get_bb_bot(coords[1], size), get_bb_top(coords[1], size, img.shape[2]))\n",
    "            bbox_y = slice(get_bb_bot(coords[0], size), get_bb_top(coords[0], size, img.shape[1]))\n",
    "            bboxes_median.append((bbox_y, bbox_x))\n",
    "\n",
    "            size = 3 * pct90_sigma\n",
    "            bbox_x = slice(get_bb_bot(coords[1], size), get_bb_top(coords[1], size, img.shape[2]))\n",
    "            bbox_y = slice(get_bb_bot(coords[0], size), get_bb_top(coords[0], size, img.shape[1]))\n",
    "            bboxes_pct90.append((bbox_y, bbox_x))\n",
    "\n",
    "            size = 3 * blobs[t][spot][2]\n",
    "            bbox_x = slice(get_bb_bot(coords[1], size), get_bb_top(coords[1], size, img.shape[2]))\n",
    "            bbox_y = slice(get_bb_bot(coords[0], size), get_bb_top(coords[0], size, img.shape[1]))\n",
    "            bboxes_indiv.append((bbox_y, bbox_x))\n",
    "\n",
    "        bbox_dict['median_sigma'].append(bboxes_median)\n",
    "        bbox_dict['pct90_sigma'].append(bboxes_pct90)\n",
    "        bbox_dict['indiv_sigma'].append(bboxes_indiv)\n",
    "    \n",
    "    # Measure median and total brightness in bboxes\n",
    "    for t in range(img.shape[0]):\n",
    "        brightness_median = []\n",
    "        brightness_total  = []\n",
    "\n",
    "        for spot in range(blobs[t].shape[0]):\n",
    "\n",
    "            # For median brightness, use individual bboxes\n",
    "            bbox_y, bbox_x = bbox_dict['indiv_sigma'][t][spot]\n",
    "            cut = img[t, bbox_y, bbox_x]\n",
    "            brightness_median.append(np.median(cut))\n",
    "\n",
    "            # For total brightness, use median bboxes\n",
    "            bbox_y, bbox_x = bbox_dict['median_sigma'][t][spot]\n",
    "            cut = img[t, bbox_y, bbox_x]\n",
    "            brightness_total.append(np.sum(cut))\n",
    "\n",
    "        # Convert results to array\n",
    "        blobs[t] = np.concatenate([blobs[t], np.array(brightness_median)[:, np.newaxis]], axis=-1)\n",
    "        blobs[t] = np.concatenate([blobs[t], np.array(brightness_total)[:, np.newaxis]], axis=-1)\n",
    "    \n",
    "    # Aggregate bbox pixel for size measurement\n",
    "    aggregated = np.array([], dtype=np.uint8)\n",
    "    for t in range(img.shape[0]):\n",
    "        for  spot in range(blobs[t].shape[0]):\n",
    "            bbox_y, bbox_x = bbox_dict['pct90_sigma'][t][spot]\n",
    "            cut = img_bgsub[t, bbox_y, bbox_x]\n",
    "            aggregated = np.concatenate([aggregated, cut.flatten()])\n",
    "\n",
    "    # Threshold on bbox pixel values\n",
    "    thresh = threshold_li(aggregated)\n",
    "    \n",
    "    # Apply threshold and measure size\n",
    "    for t in range(img.shape[0]):    \n",
    "        size_mask = []\n",
    "\n",
    "        for spot in range(blobs[t].shape[0]):\n",
    "            bbox_y, bbox_x = bbox_dict['pct90_sigma'][t][spot]\n",
    "            cut = img_bgsub[t, bbox_y, bbox_x]\n",
    "            mask = cut >= thresh\n",
    "            size_mask.append(np.sum(mask))\n",
    "\n",
    "        blobs[t] = np.concatenate([blobs[t], np.array(size_mask)[:, np.newaxis]], axis=-1)\n",
    "    \n",
    "    # Prep output path\n",
    "    out_path = img_path.replace(os.path.relpath(img_dir), os.path.relpath(out_dir))\n",
    "    out_path = out_path.replace('.tif', '_simSpots.tsv')\n",
    "    if not os.path.isdir(os.path.split(out_path)[0]):\n",
    "        os.makedirs(os.path.split(out_path)[0])\n",
    "    \n",
    "    # Write the results\n",
    "    with open(out_path, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter='\\t')\n",
    "        \n",
    "        writer.writerow(['time_step', 'spot_number', 'coord_y', 'coord_x', \n",
    "                         'blob_sigma', 'brightness_median', 'brightness_total',\n",
    "                         'size_mask', 'bbox_y_min', 'bbox_y_max', 'bbox_x_min', \n",
    "                         'bbox_x_max'])\n",
    "        \n",
    "        for t in range(img.shape[0]):\n",
    "            for spot in range(blobs[t].shape[0]):\n",
    "                writer.writerow([t, spot, blobs[t][spot,0], blobs[t][spot,1], blobs[t][spot,2], \n",
    "                                 blobs[t][spot,3], blobs[t][spot,4], blobs[t][spot,5], \n",
    "                                 bbox_dict['indiv_sigma'][t][spot][0].start, \n",
    "                                 bbox_dict['indiv_sigma'][t][spot][0].stop,\n",
    "                                 bbox_dict['indiv_sigma'][t][spot][1].start, \n",
    "                                 bbox_dict['indiv_sigma'][t][spot][1].stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='raise')\n",
    "\n",
    "for img_path in img_paths:\n",
    "    run_pipeline(img_path, min_sigma=min_sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
